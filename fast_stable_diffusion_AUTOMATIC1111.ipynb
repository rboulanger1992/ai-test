{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "Y9EBc437WDOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "47ee375d8ce44e20a3356607cf40c946",
            "b79bcac14fab47cf9b40a0e37550ac85",
            "2adf653e8496475a9a55960b71fe04be"
          ]
        },
        "outputId": "e308ff86-1623-4cb1-c6b2-df0ac41d1505"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ee375d8ce44e20a3356607cf40c946"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive\n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "CFWtw-6EPrKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4f3f3b46370640f6836d359095ea3e68",
            "6d48f1e69fa54f8ab29c2d84a12d974d",
            "4f31f13c3d254db6a32fb467a04fca02"
          ]
        },
        "outputId": "e22e3932-d2e3-4623-c4e8-7293ebda57a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f3f3b46370640f6836d359095ea3e68"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "import requests\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from tqdm import tqdm\n",
        "import six\n",
        "\n",
        "\n",
        "blsaphemy=base64.b64decode((\"ZWJ1aQ==\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using temporary colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "\n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blsaphemy+\"/cache\"\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy-assets /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/repositories/stable-diffusion-webui-assets\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "  !git reset --hard\n",
        "  !git checkout master\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "ZGV_5H4xrOSp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aa78b61df4854024a2cf42bb518fad8e",
            "48732b8060e64e9abf82d2b7d2db5fac",
            "e70bc14d63164d52b9d585c9f52b838e"
          ]
        },
        "outputId": "2037a401-abdf-46f6-afca-a06d45424a6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa78b61df4854024a2cf42bb518fad8e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/\n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusion'):\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_mrep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  if not os.path.exists('gdrive/'+mainpth+'/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "    %env CXXFLAGS=-std=c++14\n",
        "    !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "    !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "    %cd /content/gperftools\n",
        "    !patch -p1 < /content/Patch\n",
        "    !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "    !mkdir -p /content/gdrive/$mainpth/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/$mainpth/sd/libtcmalloc\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "    %cd /content\n",
        "    !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "  else:\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "\n",
        "  !pip uninstall jax -y\n",
        "  !pip install wandb==0.15.12 pydantic==1.10.2 numpy==1.24.3 controlnet_aux --no-deps -qq\n",
        "  !pip install diffusers accelerate -U --no-deps -qq\n",
        "  !rm -r /usr/local/lib/python3.11/dist-packages/tensorflow*\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.11/warnings.py\n",
        "  !sed -i 's@from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F401@@g' /usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/__init__.py\n",
        "  !sed -i 's@from .mailbox import ContextCancelledError@@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "  !sed -i 's@raise ContextCancelledError(\"retry timeout\")@print(\"retry timeout\")@g' /usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/retry.py\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p4wj_txjP3TC"
      },
      "outputs": [],
      "source": [
        "#@markdown # Model Download/Load\n",
        "\n",
        "import gdown\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "import re\n",
        "\n",
        "Use_Temp_Storage = False #@param {type:\"boolean\"}\n",
        "#@markdown - If not, make sure you have enough space on your gdrive\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"SDXL\" #@param [\"SDXL\", \"1.5\", \"v1.5 Inpainting\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown Or\n",
        "PATH_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your custom model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "src=getsrc(MODEL_LINK)\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search('attachment; filename=\"(.*?)\"', content_disposition).groups()[0]\n",
        "        return filenm\n",
        "\n",
        "\n",
        "def dwn(url, dst, msg):\n",
        "    file_size = None\n",
        "    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n",
        "    u = urlopen(req)\n",
        "    meta = u.info()\n",
        "    if hasattr(meta, 'getheaders'):\n",
        "        content_length = meta.getheaders(\"Content-Length\")\n",
        "    else:\n",
        "        content_length = meta.get_all(\"Content-Length\")\n",
        "    if content_length is not None and len(content_length) > 0:\n",
        "        file_size = int(content_length[0])\n",
        "\n",
        "    with tqdm(total=file_size, disable=False, mininterval=0.5,\n",
        "              bar_format=msg+' |{bar:20}| {percentage:3.0f}%') as pbar:\n",
        "        with open(dst, \"wb\") as f:\n",
        "            while True:\n",
        "                buffer = u.read(8192)\n",
        "                if len(buffer) == 0:\n",
        "                    break\n",
        "                f.write(buffer)\n",
        "                pbar.update(len(buffer))\n",
        "            f.close()\n",
        "\n",
        "\n",
        "def sdmdls(ver, Use_Temp_Storage):\n",
        "\n",
        "  if ver=='1.5':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v1-5-pruned-emaonly.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "  elif ver=='V2.1-768px':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v2-1_768-ema-pruned.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/v2-1_768-ema-pruned.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors'\n",
        "  elif ver=='v1.5 Inpainting':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd-v1-5-inpainting.ckpt'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt'\n",
        "  elif ver=='SDXL':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd_xl_base_1.0.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Stable-diffusion/sd_xl_base_1.0.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors'\n",
        "\n",
        "  if not os.path.exists(model):\n",
        "    !gdown --fuzzy -O $model $link\n",
        "    if os.path.exists(model):\n",
        "      clear_output()\n",
        "      inf('\\u2714 Done','success', '50px')\n",
        "    else:\n",
        "      inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "  else:\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "if (PATH_to_MODEL !=''):\n",
        "  if os.path.exists(str(PATH_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        PATH_to_MODEL=input()\n",
        "      if os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2714 Using the custom model.','success', '200px')\n",
        "\n",
        "  model=PATH_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "\n",
        "      if src=='civitai':\n",
        "         modelname=get_name(MODEL_LINK, False)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            dwn(MODEL_LINK, model, 'Downloading the custom model')\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      elif src=='gdrive':\n",
        "         modelname=get_name(MODEL_LINK, True)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      else:\n",
        "         modelname=os.path.basename(MODEL_LINK)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "      if os.path.exists(model) and os.path.getsize(model) > 1810671599:\n",
        "        inf('\\u2714 Model downloaded, using the custom model.','success', '300px')\n",
        "      else:\n",
        "        !rm model\n",
        "        inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "else:\n",
        "  model=sdmdls(Model_Version, Use_Temp_Storage)\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Svx6Hx0iUPd1"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download LoRA\n",
        "\n",
        "LoRA_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LoRA_LINK == \"\":\n",
        "  inf('\\u2714 Nothing to do','primary', '200px')\n",
        "else:\n",
        "  os.makedirs('/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/models/Lora', exist_ok=True)\n",
        "\n",
        "  src=getsrc(LoRA_LINK)\n",
        "\n",
        "  if src=='civitai':\n",
        "      modelname=get_name(LoRA_LINK, False)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        dwn(LoRA_LINK, loramodel, 'Downloading the LoRA model '+modelname)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  elif src=='gdrive':\n",
        "      modelname=get_name(LoRA_LINK, True)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "  else:\n",
        "      modelname=os.path.basename(LoRA_LINK)\n",
        "      loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blsaphemy}/models/Lora/{modelname}'\n",
        "      if not os.path.exists(loramodel):\n",
        "        gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "        clear_output()\n",
        "      else:\n",
        "        inf('\\u2714 Model already exists','primary', '200px')\n",
        "\n",
        "  if os.path.exists(loramodel) :\n",
        "    inf('\\u2714 LoRA downloaded','success', '200px')\n",
        "  else:\n",
        "    inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB"
      },
      "outputs": [],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "XL_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"Sketch\", \"OpenPose\", \"Recolor\"]\n",
        "\n",
        "v1_Model = \"None\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_canny_mid.safetensors'\n",
        "Depth='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/diffusers_xl_depth_mid.safetensors'\n",
        "Sketch='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_sketch_256lora.safetensors'\n",
        "OpenPose='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/thibaud_xl_openpose_256lora.safetensors'\n",
        "Recolor='https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/sai_xl_recolor_128lora.safetensors'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions\n",
        "  if not os.path.exists('sd-w'+blsaphemy+'-controlnet'):\n",
        "    !git clone https://github.com/Mikubill/sd-w$blsaphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-w$blsaphemy-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blsaphemy+'/extensions/sd-w'+blsaphemy+'-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "!wget -q -O CN_models_XL.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_XL.txt\n",
        "\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "with open(\"CN_models_XL.txt\", 'r') as d:\n",
        "  mdllnk_XL = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt CN_models_XL.txt\n",
        "\n",
        "\n",
        "if XL_Model == \"All\":\n",
        "  for lnk_XL in mdllnk_XL:\n",
        "      download(lnk_XL, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif XL_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[XL_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth'\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/extensions/sd-w$blsaphemy-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if v1_Model == \"All (21GB)\":\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif v1_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[v1_Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "  #@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjzwxTkPSPHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d2c368-13f9-47de-e4bb-93bd71515824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer initialized. version: \u001b[1;36m25.3\u001b[0m.\u001b[1;36m0\u001b[0m, num models: \u001b[1;36m10\u001b[0m\n",
            "ControlNet preprocessor location: /content/gdrive/MyDrive/sd/stable-diffusion-webui/extensions/sd-webui-controlnet/annotator/downloads\n",
            "2025-05-08 02:46:27,633 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet v1.1.455\n",
            "Loading weights [7c97ecf786] from /content/gdrive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/ponyRealism_V22.safetensors\n",
            "2025-05-08 02:46:29,516 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "Creating model from config: /content/gdrive/MyDrive/sd/stablediffusion/generative-models/configs/inference/sd_xl_base.yaml\n",
            "Running on public URL: https://9fb687a7087c27717c.gradio.live\n",
            "\u001b[32m✔ Connected\n",
            "Startup time: 29.5s (launcher: 0.2s, import torch: 11.0s, import gradio: 1.8s, setup paths: 2.0s, initialize shared: 0.5s, other imports: 2.1s, list SD models: 0.7s, load scripts: 4.6s, initialize extra networks: 0.5s, create ui: 1.9s, gradio launch: 3.2s, add APIs: 0.8s).\n",
            "Applying attention optimization: xformers... done.\n",
            "Model loaded in 45.6s (load weights from disk: 5.4s, create model: 1.2s, apply weights to model: 37.7s, load textual inversion embeddings: 0.2s, calculate empty prompt: 0.9s).\n",
            "100% 30/30 [00:18<00:00,  1.66it/s]\n",
            "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:335] Error parsing text-format mediapipe.CalculatorGraphConfig: 15:22: Expected identifier, got: \\\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:11<00:00,  2.60it/s]\n",
            "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:335] Error parsing text-format mediapipe.CalculatorGraphConfig: 15:22: Expected identifier, got: \\\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:11<00:00,  2.55it/s]\n",
            "\n",
            "0: 640x512 1 face, 63.4ms\n",
            "Speed: 44.1ms preprocess, 63.4ms inference, 106.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.60it/s]\n",
            "100% 30/30 [00:12<00:00,  2.50it/s]\n",
            "\n",
            "0: 640x512 2 faces, 46.5ms\n",
            "Speed: 2.6ms preprocess, 46.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.53it/s]\n",
            "100% 13/13 [00:05<00:00,  2.51it/s]\n",
            "100% 30/30 [00:23<00:00,  1.25it/s]\n",
            "\n",
            "0: 640x512 2 faces, 67.7ms\n",
            "Speed: 3.1ms preprocess, 67.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:10<00:00,  1.27it/s]\n",
            "100% 13/13 [00:10<00:00,  1.24it/s]\n",
            "100% 30/30 [00:23<00:00,  1.27it/s]\n",
            "\n",
            "0: 640x512 2 faces, 20.4ms\n",
            "Speed: 3.1ms preprocess, 20.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:10<00:00,  1.28it/s]\n",
            "100% 13/13 [00:10<00:00,  1.25it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 640x512 2 faces, 67.2ms\n",
            "Speed: 2.8ms preprocess, 67.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "100% 13/13 [00:05<00:00,  2.44it/s]\n",
            "100% 30/30 [00:12<00:00,  2.44it/s]\n",
            "\n",
            "0: 640x512 2 faces, 46.4ms\n",
            "Speed: 2.7ms preprocess, 46.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.44it/s]\n",
            "100% 13/13 [00:05<00:00,  2.40it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 640x512 2 faces, 67.8ms\n",
            "Speed: 2.9ms preprocess, 67.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "100% 13/13 [00:05<00:00,  2.45it/s]\n",
            "100% 30/30 [00:11<00:00,  2.59it/s]\n",
            "\n",
            "0: 640x512 1 face, 70.1ms\n",
            "Speed: 3.2ms preprocess, 70.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.58it/s]\n",
            "100% 30/30 [00:13<00:00,  2.24it/s]\n",
            "\n",
            "0: 640x512 2 faces, 78.0ms\n",
            "Speed: 3.1ms preprocess, 78.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.57it/s]\n",
            "100% 13/13 [00:05<00:00,  2.53it/s]\n",
            "100% 30/30 [00:11<00:00,  2.51it/s]\n",
            "\n",
            "0: 640x512 2 faces, 43.5ms\n",
            "Speed: 2.5ms preprocess, 43.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "100% 30/30 [00:13<00:00,  2.16it/s]\n",
            "\n",
            "0: 640x512 1 face, 56.7ms\n",
            "Speed: 6.9ms preprocess, 56.7ms inference, 7.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.54it/s]\n",
            "100% 30/30 [00:11<00:00,  2.53it/s]\n",
            "\n",
            "0: 640x512 1 face, 77.2ms\n",
            "Speed: 3.7ms preprocess, 77.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.53it/s]\n",
            "100% 30/30 [00:13<00:00,  2.14it/s]\n",
            "\n",
            "0: 640x512 1 face, 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "100% 30/30 [00:12<00:00,  2.48it/s]\n",
            "\n",
            "0: 640x512 1 face, 70.5ms\n",
            "Speed: 3.6ms preprocess, 70.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "100% 30/30 [00:12<00:00,  2.47it/s]\n",
            "\n",
            "0: 640x512 1 face, 69.3ms\n",
            "Speed: 3.0ms preprocess, 69.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.50it/s]\n",
            "100% 30/30 [00:12<00:00,  2.46it/s]\n",
            "\n",
            "0: 640x512 1 face, 42.2ms\n",
            "Speed: 2.6ms preprocess, 42.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.51it/s]\n",
            "100% 30/30 [00:11<00:00,  2.59it/s]\n",
            "\n",
            "0: 640x512 1 face, 71.4ms\n",
            "Speed: 3.0ms preprocess, 71.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.58it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 640x512 1 face, 63.4ms\n",
            "Speed: 4.0ms preprocess, 63.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.51it/s]\n",
            "100% 30/30 [00:12<00:00,  2.48it/s]\n",
            "\n",
            "0: 512x640 1 face, 64.3ms\n",
            "Speed: 2.9ms preprocess, 64.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.46it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 512x640 1 face, 69.0ms\n",
            "Speed: 3.1ms preprocess, 69.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.50it/s]\n",
            "100% 30/30 [00:12<00:00,  2.50it/s]\n",
            "\n",
            "0: 512x640 (no detections), 42.7ms\n",
            "Speed: 2.7ms preprocess, 42.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.46it/s]\n",
            "\n",
            "0: 512x640 (no detections), 69.1ms\n",
            "Speed: 3.2ms preprocess, 69.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:11<00:00,  2.53it/s]\n",
            "\n",
            "0: 512x640 (no detections), 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.50it/s]\n",
            "\n",
            "0: 512x640 1 face, 42.9ms\n",
            "Speed: 2.7ms preprocess, 42.9ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.50it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 512x640 1 face, 72.4ms\n",
            "Speed: 3.3ms preprocess, 72.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "100% 30/30 [00:12<00:00,  2.41it/s]\n",
            "\n",
            "0: 512x640 (no detections), 42.3ms\n",
            "Speed: 2.5ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.38it/s]\n",
            "\n",
            "0: 512x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.33it/s]\n",
            "\n",
            "0: 512x640 (no detections), 72.8ms\n",
            "Speed: 3.1ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.36it/s]\n",
            "\n",
            "0: 512x640 (no detections), 55.3ms\n",
            "Speed: 2.6ms preprocess, 55.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.36it/s]\n",
            "\n",
            "0: 512x640 (no detections), 7.0ms\n",
            "Speed: 2.5ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.32it/s]\n",
            "\n",
            "0: 512x640 (no detections), 67.6ms\n",
            "Speed: 2.9ms preprocess, 67.6ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.33it/s]\n",
            "\n",
            "0: 512x640 (no detections), 46.6ms\n",
            "Speed: 2.5ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:13<00:00,  2.30it/s]\n",
            "\n",
            "0: 512x640 2 faces, 42.7ms\n",
            "Speed: 2.6ms preprocess, 42.7ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.31it/s]\n",
            "100% 13/13 [00:05<00:00,  2.29it/s]\n",
            "100% 30/30 [00:12<00:00,  2.36it/s]\n",
            "\n",
            "0: 512x640 (no detections), 73.5ms\n",
            "Speed: 2.9ms preprocess, 73.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.31it/s]\n",
            "\n",
            "0: 512x640 (no detections), 46.4ms\n",
            "Speed: 2.6ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:13<00:00,  2.22it/s]\n",
            "\n",
            "0: 512x640 (no detections), 46.6ms\n",
            "Speed: 3.0ms preprocess, 46.6ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.33it/s]\n",
            "\n",
            "0: 512x640 (no detections), 127.3ms\n",
            "Speed: 3.7ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.33it/s]\n",
            "\n",
            "0: 512x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:13<00:00,  2.25it/s]\n",
            "\n",
            "0: 512x640 1 face, 68.1ms\n",
            "Speed: 2.8ms preprocess, 68.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.26it/s]\n",
            "100% 30/30 [00:12<00:00,  2.33it/s]\n",
            "\n",
            "0: 512x640 1 face, 42.4ms\n",
            "Speed: 2.6ms preprocess, 42.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.35it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 512x640 (no detections), 67.3ms\n",
            "Speed: 3.0ms preprocess, 67.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.43it/s]\n",
            "\n",
            "0: 512x640 2 faces, 67.7ms\n",
            "Speed: 3.6ms preprocess, 67.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.41it/s]\n",
            "100% 13/13 [00:05<00:00,  2.36it/s]\n",
            "100% 30/30 [00:12<00:00,  2.48it/s]\n",
            "\n",
            "0: 512x640 1 face, 21.0ms\n",
            "Speed: 3.8ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.47it/s]\n",
            "100% 30/30 [00:12<00:00,  2.42it/s]\n",
            "\n",
            "0: 512x640 (no detections), 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\u001b[1m[\u001b[0m-\u001b[1m]\u001b[0m ADetailer: nothing detected on image \u001b[1;36m1\u001b[0m with 1st settings.\n",
            "100% 30/30 [00:12<00:00,  2.48it/s]\n",
            "\n",
            "0: 512x640 1 face, 69.3ms\n",
            "Speed: 3.4ms preprocess, 69.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.47it/s]\n",
            "100% 30/30 [00:12<00:00,  2.43it/s]\n",
            "\n",
            "0: 512x640 1 face, 42.0ms\n",
            "Speed: 2.5ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.42it/s]\n",
            "100% 30/30 [00:12<00:00,  2.38it/s]\n",
            "\n",
            "0: 512x640 1 face, 73.3ms\n",
            "Speed: 3.0ms preprocess, 73.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "100% 13/13 [00:05<00:00,  2.37it/s]\n",
            "100% 30/30 [00:12<00:00,  2.37it/s]\n",
            "\n",
            "0: 640x512 1 face, 42.8ms\n",
            "Speed: 2.6ms preprocess, 42.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.36it/s]\n",
            "100% 30/30 [00:11<00:00,  2.53it/s]\n",
            "\n",
            "0: 640x512 1 face, 72.6ms\n",
            "Speed: 3.2ms preprocess, 72.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "100% 30/30 [00:12<00:00,  2.46it/s]\n",
            "\n",
            "0: 640x512 1 face, 42.0ms\n",
            "Speed: 2.6ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.51it/s]\n",
            "100% 30/30 [00:12<00:00,  2.46it/s]\n",
            "\n",
            "0: 640x512 1 face, 90.8ms\n",
            "Speed: 3.7ms preprocess, 90.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.46it/s]\n",
            "100% 30/30 [00:11<00:00,  2.53it/s]\n",
            "\n",
            "0: 640x512 1 face, 71.2ms\n",
            "Speed: 3.3ms preprocess, 71.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "100% 30/30 [00:12<00:00,  2.45it/s]\n",
            "\n",
            "0: 640x512 1 face, 42.5ms\n",
            "Speed: 2.8ms preprocess, 42.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.50it/s]\n",
            "100% 30/30 [00:12<00:00,  2.49it/s]\n",
            "\n",
            "0: 640x512 1 face, 18.7ms\n",
            "Speed: 3.1ms preprocess, 18.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.49it/s]\n",
            "100% 30/30 [00:12<00:00,  2.40it/s]\n",
            "\n",
            "0: 640x512 1 face, 64.8ms\n",
            "Speed: 3.6ms preprocess, 64.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 512)\n",
            "100% 13/13 [00:05<00:00,  2.42it/s]\n",
            "100% 30/30 [00:15<00:00,  1.91it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.4ms\n",
            "Speed: 6.8ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.84it/s]\n",
            "100% 30/30 [00:16<00:00,  1.85it/s]\n",
            "\n",
            "0: 640x640 1 face, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:06<00:00,  1.86it/s]\n",
            "100% 30/30 [00:16<00:00,  1.84it/s]\n",
            "\n",
            "0: 640x640 1 face, 21.9ms\n",
            "Speed: 4.2ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.82it/s]\n",
            "100% 30/30 [00:16<00:00,  1.85it/s]\n",
            "\n",
            "0: 640x640 1 face, 20.6ms\n",
            "Speed: 4.6ms preprocess, 20.6ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.80it/s]\n",
            "100% 30/30 [00:15<00:00,  1.92it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:06<00:00,  1.89it/s]\n",
            "100% 30/30 [00:16<00:00,  1.85it/s]\n",
            "\n",
            "0: 640x640 1 face, 6.9ms\n",
            "Speed: 3.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.86it/s]\n",
            "100% 30/30 [00:16<00:00,  1.84it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:06<00:00,  1.86it/s]\n",
            "100% 30/30 [00:16<00:00,  1.86it/s]\n",
            "\n",
            "0: 640x640 1 face, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.81it/s]\n",
            "100% 30/30 [00:17<00:00,  1.73it/s]\n",
            "\n",
            "0: 640x640 1 face, 13.5ms\n",
            "Speed: 4.9ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.70it/s]\n",
            "100% 30/30 [00:17<00:00,  1.75it/s]\n",
            "\n",
            "0: 640x640 1 face, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.68it/s]\n",
            "100% 30/30 [00:17<00:00,  1.73it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.75it/s]\n",
            "100% 30/30 [00:16<00:00,  1.77it/s]\n",
            "\n",
            "0: 640x640 1 face, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "100% 13/13 [00:07<00:00,  1.69it/s]\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "import re\n",
        "\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/\n",
        "  !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blsaphemy/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.11/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/\n",
        "\n",
        "  !sed -i 's@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title;model.half()@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/sd_models.py\n",
        "  #!sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/extras.py\n",
        "\n",
        "  !sed -i 's@possible_sd_paths =.*@possible_sd_paths = [\\\"/content/gdrive/{mainpth}/sd/stablediffusion\\\"]@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@\\.\\.\\/@src/@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "  !sed -i 's@src/generative-models@generative-models@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/paths.py\n",
        "\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\[\"sd_model_checkpoint\"\\]@\\[\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"inpainting_mask_weight\", \"initial_noise_multiplier\"\\]@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.11/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "ckptdir=''\n",
        "if os.path.exists('/content/temp_models'):\n",
        "  ckptdir='--ckpt-dir /content/temp_models'\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir\n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers $auth --disable-console-progressbars --skip-version-check\n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blsaphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers $auth --disable-console-progressbars --skip-version-check $ckptdir"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47ee375d8ce44e20a3356607cf40c946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_b79bcac14fab47cf9b40a0e37550ac85",
            "style": "IPY_MODEL_2adf653e8496475a9a55960b71fe04be",
            "tooltip": ""
          }
        },
        "b79bcac14fab47cf9b40a0e37550ac85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adf653e8496475a9a55960b71fe04be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4f3f3b46370640f6836d359095ea3e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_6d48f1e69fa54f8ab29c2d84a12d974d",
            "style": "IPY_MODEL_4f31f13c3d254db6a32fb467a04fca02",
            "tooltip": ""
          }
        },
        "6d48f1e69fa54f8ab29c2d84a12d974d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f31f13c3d254db6a32fb467a04fca02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "aa78b61df4854024a2cf42bb518fad8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_48732b8060e64e9abf82d2b7d2db5fac",
            "style": "IPY_MODEL_e70bc14d63164d52b9d585c9f52b838e",
            "tooltip": ""
          }
        },
        "48732b8060e64e9abf82d2b7d2db5fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70bc14d63164d52b9d585c9f52b838e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}